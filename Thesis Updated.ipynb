{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4277abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import osmnx as ox\n",
    "from datetime import datetime \n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from geopy.distance import distance\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry import LineString\n",
    "import math\n",
    "from pyproj import Geod\n",
    "import geopandas as gpd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef79b8d",
   "metadata": {},
   "source": [
    "### Finding mobile data points which are less than 2 km away from najafgarh station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e150b2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = pd.read_excel(r\"E:\\Thesis Codes\\POI Data\\stations_POI.xlsx\")\n",
    "stations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadb4218",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_njf, long_njf = stations.loc[20]['Latitude'], stations.loc[20]['Longitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9715ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_njf, long_njf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa052cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "realtime = pd.read_csv(r\"realtime_data_DEC.csv\")\n",
    "realtime2 = pd.read_csv(r\"realtime_data_JAN.csv\")\n",
    "realtime.append(realtime2, ignore_index=True)\n",
    "realtime.drop('Unnamed: 0', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e6cfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "realtime = realtime[realtime.lat != 0]\n",
    "realtime.reset_index(drop = True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658ce97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    # convert decimal degrees to radians\n",
    "    lon1, lat1, lon2, lat2 = map(math.radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    # haversine formula\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = math.sin(dlat/2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon/2)**2\n",
    "    c = 2 * math.asin(math.sqrt(a))\n",
    "\n",
    "    # Radius of earth in kilometers. Use 3956 for miles\n",
    "    r = 6371\n",
    "\n",
    "    # calculate the result\n",
    "    distance = c * r\n",
    "    return distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f4d1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_distance(df, lat, long):\n",
    "    d = []\n",
    "    for i in range(len(df)):\n",
    "        point1 = (df.loc[i,'long'], df.loc[i,'lat'])\n",
    "        point2 = (long, lat)\n",
    "        dist = haversine(lat_njf,long_njf,realtime.loc[i,'lat'],realtime.loc[i,'long'])\n",
    "        d.append(dist)\n",
    "    df['dist'] = d\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38033209",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "realtime = find_distance(realtime, lat_njf, long_njf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59c2d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "realtime = realtime[realtime.dist <= 2]\n",
    "realtime.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7643eb4",
   "metadata": {},
   "source": [
    "### Joining statc PM 2.5 with the PM 2.5 values obtained from dynamic data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82779bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_njf = pd.read_excel(r\"C:\\Users\\vinee\\Downloads\\Thesis\\PM_lodhi_road.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4b61a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "realtime.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2946f868",
   "metadata": {},
   "outputs": [],
   "source": [
    "realtime.rename(columns = {'last_updated':'From Date'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6d9925",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_njf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ff1759",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_njf['From Date'] = df_njf['From Date'].apply(lambda x : datetime.strptime(x, '%d-%m-%Y %H:%M'))\n",
    "realtime['From Date'] = realtime['From Date'].apply(lambda x : datetime.strptime(x, '%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16357c8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.merge(df_njf, realtime, on = 'From Date', how = 'inner')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61528f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'PM2.5_x' : 'PM2.5 static', 'PM2.5_y' : 'PM2.5 mobile'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8580cb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_midpoint(lat1, lng1, lat2, lng2):\n",
    "    lat_mid = (lat1 + lat2) / 2\n",
    "    long_mid = (lng1 + lng2) / 2\n",
    "    return lat_mid, long_mid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f099999",
   "metadata": {},
   "source": [
    "### Checking mid point formula is giving correct results or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98e7534",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_mid, long_mid = find_midpoint(lat_njf, long_njf, df.loc[2, 'lat'], df.loc[2,'long'])\n",
    "print(lat_mid, long_mid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c28b109",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import folium\n",
    "m = folium.Map(location=[lat_njf, long_njf], zoom_start=13)\n",
    "folium.Marker(location=[lat_njf, long_njf], popup='Point 1').add_to(m)\n",
    "folium.Marker(location=[df.loc[2, 'lat'], df.loc[2,'long']], popup='Point 2').add_to(m)\n",
    "folium.Marker(location=[lat_mid, long_mid], popup='Mid point 1').add_to(m)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c66dcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e7f0fbb",
   "metadata": {},
   "source": [
    "### Code to add POIs(count), LandUse(area), water, buildings_area in our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65fb0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to filter dataframe on basis of the buffer formed by joining the line from the static monitor to the location of data point generated by mobile monitors\n",
    "def buffer_point(df, lat, long, buffer_size):\n",
    "    df['points'] = df.apply(lambda x: [y for y in x['geometry'].coords], axis=1)\n",
    "    count = 0\n",
    "    for i in range(len(df)):\n",
    "        point1 = (df.loc[i,'points'][0][0], df.loc[i,'points'][0][1])\n",
    "        point2 = (long, lat)\n",
    "        d = haversine(lat_njf, long_njf , df.loc[i,'points'][0][1] , df.loc[i,'points'][0][0])\n",
    "        if d <= buffer_size:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "# Code to filter dataframe on basis of the buffer formed by joining the line from the static monitor to the location of data point generated by mobile monitors\n",
    "def buffer_polygon(df, point, buffer_size):\n",
    "    df = df.to_crs({'init': 'epsg:3857'})\n",
    "    point = gpd.GeoSeries(point, crs='epsg:4326').to_crs(epsg=3857).iloc[0]\n",
    "    buffer = point.buffer(buffer_size)\n",
    "    df = df[df.intersects(buffer)]\n",
    "    if df.shape[0] == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        df['area_sq_m'] = df['geometry'].area\n",
    "        return df['area_sq_m'].sum()/(10**6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcb9dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_POI(df):\n",
    "    poi = []\n",
    "    for i in tqdm(range(len(df))):\n",
    "        poi_gdf = gpd.read_file(r\"C:\\Users\\vinee\\Downloads\\Thesis\\SHP Files\\poi_count.shp\")\n",
    "        lat_mid, long_mid = find_midpoint(lat_njf, long_njf, df.loc[i, 'lat'], df.loc[i,'long'])\n",
    "        buffer_size = df.dist[i]/2\n",
    "        poi.append(buffer_point(poi_gdf, lat_mid, long_mid, buffer_size))\n",
    "    df['POI'] = poi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251ead53",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "add_POI(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6aed719",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e5e1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to convert a multipolygon in water shape file to polygon\n",
    "def process(gdf):\n",
    "    # Get the index of the row containing the MultiPolygon geometry\n",
    "    idx = gdf.index[gdf.geometry.type == 'MultiPolygon']\n",
    "    for i in idx:\n",
    "        gdf = gdf.explode(index=[i]).drop(i)\n",
    "        gdf = gdf.reset_index(drop=True)\n",
    "    return gdf\n",
    "\n",
    "def add_landuse(df):\n",
    "    area = []\n",
    "    for i in tqdm(range(len(df))):\n",
    "        landuse_gdf = gpd.read_file(r\"C:\\Users\\vinee\\Downloads\\Thesis\\SHP Files\\LandUse.shp\")\n",
    "        landuse_gdf = process(landuse_gdf)\n",
    "        lat_mid, long_mid = find_midpoint(lat_njf, long_njf, df.loc[i, 'lat'], df.loc[i,'long'])\n",
    "        buffer_size = df.dist[i]/2\n",
    "        buffer_size = buffer_size*(10**3) #Converting buffer size in metres\n",
    "        point = Point(long_mid,lat_mid)\n",
    "        area.append(buffer_polygon(landuse_gdf, point, buffer_size))\n",
    "    df['landuse(sq_km)'] = area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94544e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_landuse(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85944168",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_water(df):\n",
    "    area = []\n",
    "    for i in tqdm(range(len(df))):\n",
    "        landuse_gdf = gpd.read_file(r\"C:\\Users\\vinee\\Downloads\\Thesis\\SHP Files\\water.shp\")\n",
    "        gdf = process(landuse_gdf)\n",
    "        lat_mid, long_mid = find_midpoint(lat_njf, long_njf, df.loc[i, 'lat'], df.loc[i,'long'])\n",
    "        buffer_size = df.dist[i]/2\n",
    "        buffer_size = buffer_size*(10**3) #Converting buffer size in metres\n",
    "        point = Point(long_mid,lat_mid)\n",
    "        try:\n",
    "            area.append(buffer_polygon(gdf, point, buffer_size))\n",
    "        except:\n",
    "            area.append(0)\n",
    "    df['water(sq_km)'] = area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb9cc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_water(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15996845",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_buildings(df):\n",
    "    area = []\n",
    "    for i in tqdm(range(len(df))):\n",
    "        landuse_gdf = gpd.read_file(r\"C:\\Users\\vinee\\Downloads\\Thesis\\SHP Files\\buildings_area.shp\")\n",
    "        lat_mid, long_mid = find_midpoint(lat_njf, long_njf, df.loc[i, 'lat'], df.loc[i,'long'])\n",
    "        buffer_size = df.dist[i]/2\n",
    "        buffer_size = buffer_size*(10**3) #Converting buffer size in metres\n",
    "        point = Point(long_mid,lat_mid)\n",
    "        area.append(buffer_polygon(landuse_gdf, point, buffer_size))\n",
    "    df['buildings(sq_km)'] = area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0441a57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_buildings(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7b0771",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cd8ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'df_poi_land_buildings.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f45fb1d",
   "metadata": {},
   "source": [
    "### Code to plot the shapefile (grey color) and the common area colored blue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105a69bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# Set the CRS of the landuse_gdf to EPSG:3857\n",
    "landuse_gdf = gpd.read_file(r\"C:\\Users\\vinee\\Downloads\\Thesis\\SHP Files\\LandUse.shp\")\n",
    "landuse_gdf = landuse_gdf.to_crs(epsg=3857)\n",
    "\n",
    "# Create a shapely point object representing the point of interest\n",
    "point = Point(long_njf, lat_njf)\n",
    "\n",
    "# Set the CRS of the point to EPSG:3857\n",
    "point = gpd.GeoSeries(point, crs='epsg:4326').to_crs(epsg=3857).iloc[0]\n",
    "\n",
    "# Create a buffer around the point\n",
    "buffer = point.buffer(1000)  # buffer radius in meters\n",
    "\n",
    "# Select the landuse polygons that intersect with the buffer\n",
    "intersected = landuse_gdf[landuse_gdf.intersects(buffer)]\n",
    "\n",
    "# Create a new geopandas GeoDataFrame with the buffer polygon\n",
    "buffer_gdf = gpd.GeoDataFrame(geometry=[buffer])\n",
    "\n",
    "# Plot the buffer and the intersected polygons together\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.set_aspect('equal')\n",
    "landuse_gdf.plot(ax=ax, color='lightgray', edgecolor='black')\n",
    "intersected.plot(ax=ax, color='blue')\n",
    "#buffer_gdf.plot(ax=ax, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a336ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795a4cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.read_csv(r\"C:\\Users\\vinee\\Downloads\\Thesis\\df_thesis.csv\")\n",
    "df_final['From Date'] = df_final['From Date'].apply(lambda x : datetime.strptime(x, '%Y-%m-%d %H:%M:%S'))\n",
    "df_final['len_low_congestion'] = 0\n",
    "df_final['len_medium_congestion'] = 0\n",
    "df_final['len_high_congestion'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e449fab2",
   "metadata": {},
   "source": [
    "### Adding length of roads according to congestion factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9c6e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def traffic(lat, long, buffer_radius):\n",
    "    road_gdf = gpd.read_file(r\"C:\\Users\\vinee\\Downloads\\Thesis\\SHP Files\\roads.shp\")\n",
    "    road_gdf = road_gdf.to_crs({'init': 'epsg:3857'})\n",
    "    point = Point(long, lat)\n",
    "    point = gpd.GeoSeries(point, crs='epsg:4326').to_crs(epsg=3857).iloc[0]\n",
    "    buffer = point.buffer(buffer_radius)\n",
    "    intersected = road_gdf[road_gdf.intersects(buffer)]\n",
    "    intersected = intersected.reset_index(drop=True)\n",
    "    return intersected\n",
    "\n",
    "def date_time(date_obj):\n",
    "    return datetime.strftime(date_obj, '%d-%b-%Y-%H-%M')\n",
    "\n",
    "def to_date_time(x):\n",
    "    return datetime.strptime(x,'%d-%b-%Y-%H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23b8dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(r\"E:\\HERE\")\n",
    "d = {'00':[], '15':[], '30':[], '45':[]}\n",
    "for i in range(len(files)):\n",
    "    dist = 1e3\n",
    "    key = ''\n",
    "    for j in d:\n",
    "        diff = abs(int(files[i][-6:-4]) - int(j))\n",
    "        if diff < dist:\n",
    "            key = j\n",
    "            dist = diff\n",
    "    d[key].append(i)\n",
    "l1 = d['00']\n",
    "l2 = d['15']\n",
    "l3 = d['30']\n",
    "l4 = d['45']\n",
    "\n",
    "lst_files = []\n",
    "for i in l1:\n",
    "    lst_files.append(files[i])\n",
    "for i in l2:\n",
    "    lst_files.append(files[i])\n",
    "for i in l3:\n",
    "    lst_files.append(files[i])\n",
    "for i in l4:\n",
    "    lst_files.append(files[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76338bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df.copy()\n",
    "for j in tqdm(range(len(df_final))):\n",
    "    dt = df_final.loc[j,'From Date']\n",
    "    lat_mid, long_mid = find_midpoint(lat_njf, long_njf, df_final.loc[j, 'lat'], df_final.loc[j,'long'])\n",
    "    buffer_size = df_final.dist[j]/2\n",
    "    buffer_size = buffer_size*(10**3)\n",
    "    intersected = traffic(lat_mid, long_mid, buffer_size)\n",
    "    for i in lst_files:\n",
    "        congestion = []\n",
    "        str_dt_time = i[:-7]\n",
    "        dt_time = to_date_time(str_dt_time)\n",
    "        if dt_time == dt:\n",
    "            path = \"E:\\\\HERE\\\\\" + i\n",
    "            df = pd.read_csv(path)\n",
    "            all_roads = df['Names'].unique()\n",
    "            for i in range(len(intersected)):\n",
    "                if(intersected.loc[i,'name'] in all_roads):\n",
    "                    ff = df[df['Names']==intersected.loc[i,'name']].ff.mean()\n",
    "                    su = df[df['Names']==intersected.loc[i,'name']].su.mean()\n",
    "                    if su == 0:\n",
    "                        congestion.append(0)\n",
    "                    else:\n",
    "                        val = ff/su\n",
    "                        if val > 1:\n",
    "                            congestion.append(1)\n",
    "                        else:\n",
    "                            congestion.append(val)\n",
    "                else:\n",
    "                    congestion.append(0)\n",
    "            intersected['congestion_factor'] = congestion\n",
    "            congestion_low = intersected[intersected['congestion_factor'] <= 0.3]\n",
    "            congestion_low = congestion_low[congestion_low.name.isna()]\n",
    "            congestion_low = congestion_low.reset_index(drop=True)\n",
    "            congestion_medium = intersected[(intersected['congestion_factor'] > 0.3) & (intersected['congestion_factor'] <= 0.7)]\n",
    "            congestion_medium = congestion_medium.reset_index(drop=True)\n",
    "            congestion_high = intersected[intersected['congestion_factor'] > 0.7]\n",
    "            congestion_high = congestion_high.reset_index(drop=True)\n",
    "            df_final.at[j,'len_low_congestion'] = congestion_low.geometry.length.sum()/(1000)\n",
    "            df_final.at[j,'len_medium_congestion'] = congestion_medium.geometry.length.sum()/(1000)\n",
    "            df_final.at[j,'len_high_congestion'] = congestion_high.geometry.length.sum()/(1000)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379f595a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb394624",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv('df4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765bb071",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final[df_final.len_medium_congestion > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d61395",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68c5a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f538913a",
   "metadata": {},
   "outputs": [],
   "source": [
    "landuse_gdf = gpd.read_file(r\"C:\\Users\\vinee\\Downloads\\Thesis\\SHP Files\\LandUse.shp\")\n",
    "landuse_gdf.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf446003",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
